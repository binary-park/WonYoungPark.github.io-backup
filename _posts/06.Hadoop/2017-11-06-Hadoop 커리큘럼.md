---
layout: post
title: "Hadoop 커리큘럼"
subtitle: "Hadoop"
categories: document
tags: hadoop
comments: true
---

### 1. Hadoop의 핵심 개념

분산저장과 분산처리

### 2. Apache Spark, Apache Hive

데이터 처리의 효율을 높이기 위해 MapReduce의 약점을 보완함.

### 3. Hadoop과 Spark의 관계

Hadoop과 Spark는 상호보완적 관계이다. Hadoop의 분산저장 기능을 Spark는 대체할 수 없다. 때문에 Spark만 사용하면 데이터 처리 효율이 떨어지게 된다. 게다가 Hadoop의 MapReduce를 사용하려면 직접 Java코딩을 해야만 한다. 무적 번거로운 이 작업을 Hive가 보완해 준다.

- 데이터 저장에는 Hadoop HDFS
- 분산처리에는 Spark
- SQL 사용에는 Hive

### 4. 커리큘럼

#### 4.1. Hadoop 기초와 빅데이터 플랫폼의 개념 및 설계

##### 4.1.1. 빅데이터 분석의 근간이 되는 빅데이터 플랫폼의 개념을 이해하고, 왜 Hadoop을 써야하는지 배워봅니다.

- 빅데이터 플랫폼의 이해
- Hadoop 에코시스템 기술의 이해(수집,저장,처리,분석)
- Hadoop 분산파일시스템(HDFS)의 구현원리
- Hadoop 맵리듀스(MapReduce)의 이해

##### 4.1.2. 빅데이터 플랫폼이 어떻게 생겼는지, 그 아키텍처를 알아보고 실무에서 빅데이터 플랫폼을 도입할 때 고려해야 할 사항들을 살펴봅니다.

- 빅데이터 플랫폼 설계 방안
- H/W와 N/W 구성
- 빅데이터 플랫폼 구축을 위한 인프라 설계
- 빅데이터 플랫폼 구축 프로세스와 설치

#### 4.2. Hadoop을 이용한 빅데이터,플랫폼 구축

##### 4.2.1. 버츄얼 박스(Virtual box)를 이용하여 설치 실습에 필요한 환경을 준비합니다. Apache Hadoop 수동설치를 통해 실제 Hadoop 플랫폼 구축할때 어떻게 Customizing하는지를 배웁니다.

- 가상머신 생성 및 리눅스 설정
- Apache Hadoop 2.X 설치

##### 4.2.2. Hadoop의 꽃인 분산환경 설정법을 배우고 실제로 데이터를 분산처리해봅니다.

- 가상머신 복제(4대)와 분산환경 설정
- Hadoop 완전 분산모드 설정 및 확장

#### 4.3. 효율적인 데이터 처리를 위한 Hadoop, Hive, Spark

##### 4.3.1. Spark는 MapReduce의 느릿느릿한 데이터 처리속도의 문제점을 해결합니다.

- Spark의 이해
- Spark 설치 및 기본 사용법

##### 4.3.2. Hive는 사용법이 어려운 MapReduce 대신 Hadoop에서 SQL을 사용할 수 있게 해줍니다.

- Hadoop 명령어 실습, HDFS 설정 및 활용
- Hive의 이해와 설치(Apache, PHP, MySQL 포함)

##### 4.3.3. SQL로 쉽게, Spark로 빠르게 데이터를 처리해봅니다.

- Hive on Spark의 이해와 실습
- Spark 기반의 Hive의 이해
- SQL 활용 실습(DDL, Query)

##### 4.3.4. Spark, 실무에서 제대로 사용하면 데이터 처리 효율을 극대화됩니다.

- Spark RDD의 이해
- Spark Operation 실습